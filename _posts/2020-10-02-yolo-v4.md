---
layout: post
title: "YOLOv4 - nhanh hơn, chính xác hơn nữa !"
description: "YOLOv4 đã có những cải thiện đáng kể, giúp tăng độ chính xác so với YOLOv3 mà không gây ảnh hưởng đến yếu tố tốc độ."
thumb_image: "yolo-v4/yolov4_compare_figure.png"
tags: [deep-learning, computer-vision]
---

## Nội dung chính

1. [Giới thiệu](#1-giới-thiệu)
2. [Cải tiến](#2-cải-tiến)
3. [Thiết kế YOLOv4](#3-thiết-kế-yolov4)
4. [Thực nghiệm](#4-thực-nghiệm)
5. [Kết luận](#5-kết-luận)

## 1. Giới thiệu

YOLOv4 đã giải quyết hai bài toán rất thực tế:

- Làm sao để có thể training model hiệu quả với một GPU duy nhất (GTX 1080Ti, RTX 2080Ti) ?
- Làm sao để model có thể đạt tốc độ real-time trên các thiết bị GPU (Maxwell/Pascal/Volta) ?

Xuyên suốt paper dài 17 trang, nhóm tác giả ghi ra chi tiết từng bước training và các thay đổi nhỏ trong model giúp tăng độ chính xác mà không ảnh hưởng nhiều đến tốc độ chay của model.

Do vậy, YOLOv4 được hưởng ứng khá rộng rãi bởi cộng đồng coder trong thời gian ngắn. Bạn có thể dễ dàng triển khai YOLOv4 trên mọi ngôn ngữ hay nền tảng: darknet, tensorflow, pytorch, keras, caffe, matlab, tensorrt, tensorflow lite, ... Thậm chí, NVIDIA gần đây mới public code triển khai YOLOv4 cho Deepstream 5.0.

Thế nên ta không còn phải hoài nghi về tính trung thực của paper YOLOv4 nữa. Hãy cùng đào sâu hơn nào!

{% include image.html path="yolo-v4/yolov4_compare_figure.png" path-detail="yolo-v4/yolov4_compare_figure.png" alt="so sánh YOLOv4 với các mô hình state-of-the-art khác" caption="YOLOv4 chạy nhanh gấp đôi so với EfficientDet với hiệu suất tương đương. Cải tiến YOLOv3 Average Precision tăng 10% và FPS tăng 12%. Lưu í rằng, vùng màu xanh thể hiện mô hình có thể chạy với tốc độ real-time." source="https://arxiv.org/pdf/2004.10934.pdf" %}

## 2. Cải tiến

Nhóm tác giả chia các phương pháp cải tiến model ra thành hai loại chính:

### Loại 1: Bag of Freebies (BoF)

> Các phương pháp giúp model tăng độ chính xác mà không làm giảm tốc độ chạy. Những phương pháp này đạt được nhờ chiến thuật training đúng đắn, chỉ tăng chi phí khi training.

### Loại 2: Bag of Special (BoS)

> Các phương pháp hoặc các mô-đun ảnh hưởng nhẹ đến tốc độ chạy, nhưng đem cải thiện độ chính xác cho model một cách đáng kể.

<style>
    table, th, td{
        border: solid #000 1px;
    }
</style>
<table>
    <tbody>
        <tr>
            <th></th>
            <th align="center">Backbone</th>
            <th align="center">Detector</th>
        </tr>
        <tr>
            <td>Bag of Freebies</td>
            <td>
                <ul>
                    <li>CutMix, Mosaic data augmentation</li>
                    <li>DropBlock regularization</li>
                    <li>Class label smoothing</li>
                </ul>
            </td>
            <td>
                <ul>
                    <li>Mosaic data augmentation</li>
                    <li>DropBlock regularization</li>
                    <li>CIoU-loss</li>
                    <li>CmBN</li>
                    <li>Self-Adversarial Training</li>
                    <li>Eliminate grid sensitivity</li>
                    <li>Sử dụng nhiều anchors cho một groud truth</li>
                    <li>Cosine annealing scheduler</li>
                    <li>Optimal hyper-parameters</li>
                    <li>Random training shapes</li>
                </ul>
            </td>
        </tr>
        <tr>
            <td>
                Bag of Specials
            </td>
            <td>
                <ul>
                    <li>Mish activation</li>
                    <li>Cross-stage partial connections (CSP)</li>
                    <li>Multi-input weighted residual connectios (MiWRC)</li>
                </ul>
            </td>
            <td>
                <ul>
                    <li>Mish activation</li>
                    <li>SPP-block</li>
                    <li>SAM-block</li>
                    <li>PAN path-aggregation block</li>
                    <li>DIoU-NMS</li>
                </ul>
            </td>
        </tr>
    </tbody>
</table>

Vì có quá nhiều tối ưu được áp dụng cho YOLOv4, nên mình sẽ chỉ đề cập đến những biến đổi quan trọng liên quan đến cấu trúc mạng trong chi tiết phần tới. Những tối ưu liên quan đến phương pháp data augmentation, hàm activation, hàm loss hay quá trình training ... mình sẽ đề cập đến trong những bài viết sau.


## 3. Thiết kế YOLOv4

Thiết kế của YOLOv4 được mô tả như sau:

### 3.1. Backbone: CSPDarknet53

Trong phiên bản trước, YOLOv3 sử dụng Darknet-53 làm backbone. Darknet-53 là sự kết hợp giữa backbone được dùng trong YOLOv2, Darknet-19, và cấu trúc Residual Networks.

{% include image.html path="yolo-v4/darknet-53.png" path-detail="yolo-v4/darknet-53.png" alt="Cấu trúc Darknet-53" caption="Cấu trúc Darknet-53." source="https://arxiv.org/pdf/1804.02767.pdf"%}

Trong phiên bản này, YOLOv4 đã cải tiến mô hình Darknet-53 bằng cách thay các khối ResNet thông thường bằng các khối CSPResNet. Theo báo cáo từ paper CSPNet (Cross Stage Partial Network), cấu trúc mới này giúp tăng khả năng học của mạng CNN, giảm khối lượng tính toán và giảm chi phí bộ nhớ. Cụ thể hơn, CSPNet có thể ứng dụng dễ dàng trên ResNet, ResNeXt, và DenseNet. Việc ứng dụng CSPNet trên các mạng này giúp giảm khối lượng tính toán từ 10% đến 20%, trong khi vượt trội hơn về độ chính xác trong bài toán phân loại ảnh trên tập ImageNet.

{% include image.html path="yolo-v4/CSPNet_performance.png" path-detail="yolo-v4/CSPNet_performance.png" alt="Tính hiệu quả của CSPNet" caption="CSPNet có thể ứng dụng trên ResNet, ResNeXt, DenseNet, etc. Cấu trúc mới không chỉ giảm chi phí tính toán, bộ nhớ, mà còn giúp tăng tốc độ và độ chính xác." source="https://arxiv.org/pdf/1911.11929.pdf" %}

Cách áp dụng CSPNet cho ResNet hay ResNeXt rất đơn giản. Bằng cách giảm một nửa số feature channels được phép đi qua khối Residual, không cần sử dụng đến Bottleneck Layer để giảm khối lượng tính toán nữa.

{% include image.html path="yolo-v4/CSPResNeXt.png" path-detail="yolo-v4/CSPResNeXt.png" alt="Ứng dụng CSPNet trên ResNeXt" caption="Ứng dụng CSPNet trên ResNeXt." source="https://arxiv.org/pdf/1911.11929.pdf"%}


Ngoài ra, để đạt được độ tối ưu về cả tốc độ và độ chính xác, chúng ta cần quan tâm đến sự cân bằng giữa kích thước ảnh đầu vào, số lượng lớp Convolution, số lượng tham số và số lượng lớp đầu ra. Ví dụ, một số nghiên cứu chỉ ra rằng CSPResNeXt50 tốt hơn CSPDarknet53 trong bài toán Object Classification trên tập dữ liệu ImageNet. Tuy nhiên, ngược lại, CSPDarknet53 lại tốt hơn CSPResNeXt50 trong bài toán Object Detection trên tập dữ liệu COCO. Như vậy, một mô hình tối ưu cho bài toán Object Classification chưa chắc đã tối ưu cho bài toán Object Detection. Một số lưu ý ta cần quan tâm như sau:

* Kích thước ảnh đầu vào lớn - tốt hơn cho việc phát hiện vật thể nhỏ.
* Nhiều layer - tăng kích thước reception field, tăng khả năng khái quát hóa.
* Nhiều tham số  - tăng khả năng phát hiện các vật thể với kích thước khác nhau trên một ảnh.

{% include image.html path="yolo-v4/backbone-selection.png" path-detail="yolo-v4/backbone-selection.png" alt="Tham số của các mô hình mạng phân loại ảnh" caption="Tham số của các mô hình mạng phân loại ảnh." source="https://arxiv.org/pdf/2004.10934.pdf" %}

Trong hình ảnh so sánh trên, đối với cùng một kích thước ảnh đầu vào, ta có thể thấy CSPDarknet53 có kích thước receptive field, số lượng tham số và tốc độ vượt trội hơn hẳn CSPResNeXt50. 

### 3.2. Neck: SPP, PAN

#### 3.2.1. Spatial Pyramid Pooling (SPP)

YOLOv3 detect object có kích cỡ đa dạng dựa trên việc concat các global feature của nhiều lớp convolution có kích cỡ khác nhau. Tuy nhiên, YOLOv3 đã bỏ qua việc kết hợp các local region features với kích cỡ khác nhau tại cùng một lớp convolution. Chính vì vậy, nhóm tác giả đã thêm vào YOLOv4 một khối Space Pyramid Pooling. YOLOv4 có thể tối ưu cả những global feature và local region feature có kích cỡ đa dạng, tăng số lượng receptive field.

{% include image.html path="yolo-v4/SPP.png" path-detail="yolo-v4/SPP.png" alt="Spatial Pyramid Pooling" caption="Spatial Pyramid Pooling đã cải tiến để tích hợp vào YOLOv4." source="https://arxiv.org/pdf/1903.08589.pdf" %}


#### 3.2.2. Path Aggregation Network (PAN)

Nếu như YOLOv3 sử dụng FPN (Feature Pyramid Network) để tổng hợp các global feature ở những tầng convolution khác nhau, thì YOLOv4 đã sử dụng một phiên bản nâng cấp hơn là PAN (Path Aggregation Network).

{% include image.html path="yolo-v4/FPN_PAN.png" path-detail="yolo-v4/FPN_PAN.png" alt="FPN vs PAN" caption="Feature network design (a) FPN thêm một nhánh top-down giúp tổng hợp những global feature có kích cỡ khác nhau từ tầng 3 tới tầng 7 (P3-P7) (b) PANet thêm một nhánh bottom-up so với FPN" source="https://arxiv.org/pdf/1911.09070.pdf" %}

Tuy nhiên, việc sử dụng FPN của YOLOv3 có một điểm yếu. YOLOv3 sử dụng FPN và detect object tại 3 tầng khác nhau một cách độc lập. Việc này dẫn đến sự trùng lặp trong dự đoán và không tối ưu việc tổng hợp thông tin của các feature map. Ngược lại, YOLOv4 sử dụng cấu trúc PAN, tổng hợp thông tin từ tất cả các tầng tại một đầu ra duy nhất.


### 3.3. Head: YOLOv3

YOLOv4 vẫn giữ nguyên cấu trúc head (anchor based) từ YOLOv3.

## 4. Thực nghiệm

So sánh kết quả đạt được cùng với các mô hình State of The Art object detection khác ở hình dưới. YOLOv4 là mô hình tối ưu nhất cả về mặt tốc độ lãn độ chính xác. 

{% include image.html path="yolo-v4/yolov4_compare_full.png" path-detail="yolo-v4/yolov4_compare_full.png" alt="YOLO v4 so sánh với những mạng object detection khác." caption="So sánh về tốc độ và độ chính xác của các mô hình object detection khác nhau trên các loại GPUs (Maxwell/Pascal/Volta)." source="https://arxiv.org/pdf/2004.10934.pdf" %}


## 5. Kết luận

YOLOv4 đưa ra một hướng đi rất cụ thể cho việc cải tiến YOLOv3. Bằng việc liệt kê tất cả các phương pháp cải tiến mới hiện tại, nhóm tác giả chọn ra những cải tiến phù hợp nhất mà không gây ảnh hưởng nhiều đến tốc độ. Sau đây, mình xin được liệt kê các source code từ github đã implement YOLOv4. Trong tương lai mình sẽ tự thử nghiệm và đưa ra đánh giá cụ thể hơn.

* [Darknet (source code gốc của tác giả)](https://github.com/AlexeyAB/darknet){:target='_blank'}
* [Tensorflow, TFlite, Android](https://github.com/hunglc007/tensorflow-yolov4-tflite){:target='_blank'}
* [Pytorch, ONNX và TensorRT](https://github.com/Tianxiaomo/pytorch-YOLOv4){:target='_blank'}
* [TensorRT](https://github.com/wang-xinyu/tensorrtx){:target='_blank'}
* [Deepstream](https://github.com/NVIDIA-AI-IOT/yolov4_deepstream){:target='_blank'}